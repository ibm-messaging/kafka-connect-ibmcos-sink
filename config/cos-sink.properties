name=cos-sink
connector.class=com.ibm.eventstreams.connect.cossink.COSSinkConnector

# You can increase this for higher throughput
tasks.max=1

# The list of source Kafka topics (comma separated, no spaces)
topics=<TOPIC>

key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter


# (required) - API key used to connect to the Object Storage service instance.
cos.api.key=<COS_APIKEY>
# (required) - Location of the Object Storage service bucket, for example: eu-gb.
cos.bucket.location=<COS_LOCATION>
# (required) - Name of the Object Storage service bucket to write data into.
cos.bucket.name=<BUCKET_NAME>
# (required) - Resiliency of the Object Storage bucket. Must be one of: cross-region, regional, or single-site.
cos.bucket.resiliency=regional
# (optional) - Specify public to connect to the Object Storage service over the public internet, or private to connect from a connector running inside the IBM Cloud network, for example from an IBM Cloud Kubernetes Service cluster. The default is public.
cos.endpoint.visibility=public
# (optional) - The number of seconds (as measured wall clock time for the Connect Task instance) between reading the first record from Kafka, and writing all of the records read so far into an object storage object. This can be useful in situations where there are long pauses between Kafka records being produced to a topic, as it ensures that any records received by this connector will always be written into object storage within the specified period of time.
cos.object.deadline.seconds=5
# (optional) - The number of seconds (as measured by the timestamps in Kafka records) between reading the first record from Kafka, and writing all of the records read so far into an object storage object.
cos.object.interval.seconds=5
# (optional) - The maximum number of Kafka records to combine into a object.
cos.object.records=5
# (required) - CRN for the Object Storage service instance.
cos.service.crn=<COS_CRN>
